{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>887</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Montvila, Rev. Juozas</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211536</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Graham, Miss. Margaret Edith</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112053</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>B42</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>889</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>W./C. 6607</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>890</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Behr, Mr. Karl Howell</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111369</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C148</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>891</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Dooley, Mr. Patrick</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>370376</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass  \\\n",
       "0              1         0       3   \n",
       "1              2         1       1   \n",
       "2              3         1       3   \n",
       "3              4         1       1   \n",
       "4              5         0       3   \n",
       "..           ...       ...     ...   \n",
       "886          887         0       2   \n",
       "887          888         1       1   \n",
       "888          889         0       3   \n",
       "889          890         1       1   \n",
       "890          891         0       3   \n",
       "\n",
       "                                                  Name     Sex   Age  SibSp  \\\n",
       "0                              Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                               Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                             Allen, Mr. William Henry    male  35.0      0   \n",
       "..                                                 ...     ...   ...    ...   \n",
       "886                              Montvila, Rev. Juozas    male  27.0      0   \n",
       "887                       Graham, Miss. Margaret Edith  female  19.0      0   \n",
       "888           Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN      1   \n",
       "889                              Behr, Mr. Karl Howell    male  26.0      0   \n",
       "890                                Dooley, Mr. Patrick    male  32.0      0   \n",
       "\n",
       "     Parch            Ticket     Fare Cabin Embarked  \n",
       "0        0         A/5 21171   7.2500   NaN        S  \n",
       "1        0          PC 17599  71.2833   C85        C  \n",
       "2        0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3        0            113803  53.1000  C123        S  \n",
       "4        0            373450   8.0500   NaN        S  \n",
       "..     ...               ...      ...   ...      ...  \n",
       "886      0            211536  13.0000   NaN        S  \n",
       "887      0            112053  30.0000   B42        S  \n",
       "888      2        W./C. 6607  23.4500   NaN        S  \n",
       "889      0            111369  30.0000  C148        C  \n",
       "890      0            370376   7.7500   NaN        Q  \n",
       "\n",
       "[891 rows x 12 columns]"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Import necessary libraries\n",
    "import pandas as pd  # For data manipulation and analysis\n",
    "import numpy as np  # For numerical computations\n",
    "from sklearn.impute import SimpleImputer  # For handling missing values\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder  # For data preprocessing\n",
    "from sklearn.model_selection import train_test_split  # For splitting data into training and testing sets\n",
    "from sklearn.neural_network import MLPClassifier  # For scikit-learn's MLP classifier\n",
    "from keras.models import Sequential  # For Keras' sequential model\n",
    "from keras.layers import Dense  # For Keras' dense layer\n",
    "from sklearn.metrics import accuracy_score  # For calculating accuracy\n",
    "import matplotlib.pyplot as plt  # For plotting\n",
    "\n",
    "# Load the Titanic dataset from a CSV file\n",
    "df = pd.read_csv('titanic.csv')\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.drop_duplicates(inplace=True)import heapq\n",
    "\n",
    "class PuzzleNode:\n",
    "    def __init__(self, state, parent=None, move=0, depth=0):\n",
    "        self.state = state\n",
    "        self.parent = parent\n",
    "        self.move = move\n",
    "        self.depth = depth\n",
    "        self.manhattan = self.calculate_manhattan()\n",
    "\n",
    "  \n",
    "\n",
    "def get_neighbors(node):\n",
    "    neighbors = []\n",
    "    for i in range(3):\n",
    "        for j in range(3):\n",
    "            if node.state[i][j] == 0:\n",
    "                x, y = i, j\n",
    "                break\n",
    "    moves = [(0, 1), (0, -1), (1, 0), (-1, 0)]\n",
    "    for dx, dy in moves:\n",
    "        new_x, new_y = x + dx, y + dy\n",
    "        if 0 <= new_x < 3 and 0 <= new_y < 3:\n",
    "            new_state = [row[:] for row in node.state]\n",
    "            new_state[x][y], new_state[new_x][new_y] = new_state[new_x][new_y], new_state[x][y]\n",
    "            neighbors.append(PuzzleNode(new_state, parent=node, move=(new_x, new_y), depth=node.depth + 1))\n",
    "    return neighbors\n",
    "\n",
    "def reconstruct_path(node):\n",
    "    path = []\n",
    "    while node:\n",
    "        path.append(node.state)\n",
    "        node = node.parent\n",
    "    return path[::-1]\n",
    "\n",
    "def astar_search(initial_state):\n",
    "    start_node = PuzzleNode(initial_state)\n",
    "    if start_node.manhattan == 0:\n",
    "        return [start_node.state]\n",
    "    frontier = [start_node]\n",
    "    explored = set()\n",
    "    while frontier:\n",
    "        node = heapq.heappop(frontier)\n",
    "        if node.state == [[1,2,3],[4,5,6],[7,8,0]]:\n",
    "            return reconstruct_path(node)\n",
    "        explored.add(tuple(map(tuple, node.state)))\n",
    "        for neighbor in get_neighbors(node):\n",
    "            if tuple(map(tuple, neighbor.state)) not in explored:\n",
    "                heapq.heappush(frontier, neighbor)\n",
    "\n",
    "# Example usage\n",
    "initial_state = [[1, 2, 3], [4, 0, 6], [7, 5, 8]]\n",
    "solution = astar_search(initial_state)\n",
    "for step in solution:\n",
    "    print(step)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary columns from the dataset\n",
    "df.drop(['PassengerId', 'Name', 'Ticket', 'Cabin','Embarked'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23.4500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Survived  Pclass  Sex   Age  SibSp  Parch     Fare\n",
       "0           0       3    1  22.0      1      0   7.2500\n",
       "1           1       1    0  38.0      1      0  71.2833\n",
       "2           1       3    0  26.0      0      0   7.9250\n",
       "3           1       1    0  35.0      1      0  53.1000\n",
       "4           0       3    1  35.0      0      0   8.0500\n",
       "..        ...     ...  ...   ...    ...    ...      ...\n",
       "886         0       2    1  27.0      0      0  13.0000\n",
       "887         1       1    0  19.0      0      0  30.0000\n",
       "888         0       3    0   NaN      1      2  23.4500\n",
       "889         1       1    1  26.0      0      0  30.0000\n",
       "890         0       3    1  32.0      0      0   7.7500\n",
       "\n",
       "[891 rows x 7 columns]"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a LabelEncoder object\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "gender_encoded=encoder.fit_transform(df['Sex'])\n",
    "df['Sex']=gender_encoded\n",
    "\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.dropna of      Survived  Pclass  Sex   Age  SibSp  Parch     Fare\n",
       "0           0       3    1  22.0      1      0   7.2500\n",
       "1           1       1    0  38.0      1      0  71.2833\n",
       "2           1       3    0  26.0      0      0   7.9250\n",
       "3           1       1    0  35.0      1      0  53.1000\n",
       "4           0       3    1  35.0      0      0   8.0500\n",
       "..        ...     ...  ...   ...    ...    ...      ...\n",
       "886         0       2    1  27.0      0      0  13.0000\n",
       "887         1       1    0  19.0      0      0  30.0000\n",
       "888         0       3    0   NaN      1      2  23.4500\n",
       "889         1       1    1  26.0      0      0  30.0000\n",
       "890         0       3    1  32.0      0      0   7.7500\n",
       "\n",
       "[891 rows x 7 columns]>"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove rows with missing values from the dataframe\n",
    "df.dropna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace all occurrences of '-' with NaN (Not a Number) in the dataframe\n",
    "df.replace('-', np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute missing values in the dataframe using the mean strategy\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "df = pd.DataFrame(imputer.fit_transform(df), columns=df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the dataframe to have zero mean and unit variance\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(df)\n",
    "normalized_data = scaler.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "target=df['Survived']\n",
    "train_data, test_data, train_target, test_target = train_test_split(df, target, test_size=0.2, random_state=42)\n",
    "print(train_data.shape, test_data.shape, train_target.shape, test_target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the training and testing data using the StandardScaler\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(train_data)\n",
    "X_test_scaled = scaler.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-19 {color: black;}#sk-container-id-19 pre{padding: 0;}#sk-container-id-19 div.sk-toggleable {background-color: white;}#sk-container-id-19 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-19 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-19 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-19 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-19 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-19 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-19 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-19 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-19 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-19 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-19 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-19 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-19 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-19 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-19 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-19 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-19 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-19 div.sk-item {position: relative;z-index: 1;}#sk-container-id-19 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-19 div.sk-item::before, #sk-container-id-19 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-19 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-19 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-19 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-19 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-19 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-19 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-19 div.sk-label-container {text-align: center;}#sk-container-id-19 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-19 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-19\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(alpha=0.001, batch_size=100, hidden_layer_sizes=(50, 50),\n",
       "              max_iter=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" checked><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(alpha=0.001, batch_size=100, hidden_layer_sizes=(50, 50),\n",
       "              max_iter=1000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MLPClassifier(alpha=0.001, batch_size=100, hidden_layer_sizes=(50, 50),\n",
       "              max_iter=1000)"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train scikit-learn MLP model\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(50, 50), activation='relu', solver='adam', alpha=0.001, batch_size=100, max_iter=1000)\n",
    "mlp.fit(X_train_scaled, train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a neural network model with two hidden layers\n",
    "model = Sequential()\n",
    "model.add(Dense(2, input_dim=3, activation='sigmoid'))  # Hidden layer with 2 units\n",
    "model.add(Dense(2, activation='sigmoid'))  # Output layer with 2 units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the neural network model with mean squared error loss, stochastic gradient descent optimizer, and accuracy metric\n",
    "model.compile(loss='mean_squared_error', optimizer='sgd', metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a list of Multi-Layer Perceptron (MLP) classifiers with varying hidden layer sizes\n",
    "models_MLP = [\n",
    "MLPClassifier(hidden_layer_sizes=(10,), max_iter=100),\n",
    "MLPClassifier(hidden_layer_sizes=(10,20), max_iter=100),\n",
    "MLPClassifier(hidden_layer_sizes=(10, 20, 50), max_iter=100),\n",
    "MLPClassifier(hidden_layer_sizes=(10, 20, 50, 100), max_iter=100) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a list of Keras neural network models with varying complexity\n",
    "\n",
    "Models_Keras = [\n",
    "Sequential([\n",
    "Dense(10, input_dim=7, activation='relu'), \n",
    "Dense(1, activation='sigmoid') \n",
    "]),\n",
    "Sequential([\n",
    "Dense(10, input_dim=7, activation='relu'), \n",
    "Dense(20, activation='relu'), \n",
    "Dense(1, activation='sigmoid')\n",
    "]),\n",
    "Sequential([\n",
    "Dense(10, input_dim=7, activation='relu'),\n",
    "Dense(20, activation='relu'), \n",
    "Dense(50, activation='relu'), \n",
    "Dense(1, activation='sigmoid') \n",
    "]),\n",
    "Sequential([\n",
    "Dense(10, input_dim=7, activation='relu'), \n",
    "Dense(20, activation='relu'), \n",
    "Dense(50, activation='relu'), \n",
    "Dense(100, activation='relu'), \n",
    "Dense(1, activation='sigmoid') \n",
    "])\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7262569832402235\n",
      "0.8044692737430168\n",
      "0.9497206703910615\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the accuracy of each MLP model in the list\n",
    "\n",
    "accuracy_mlp = [] \n",
    "\n",
    "for model in models_MLP: \n",
    "    # Train the model on the training data\n",
    "    model.fit(train_data, train_target) \n",
    "\n",
    "    # Use the trained model to predict the test data\n",
    "    y_pred = model.predict(test_data) \n",
    "\n",
    "    # Calculate the accuracy of the model and append it to the accuracy list\n",
    "    accuracy_mlp.append(accuracy_score(test_target, y_pred)) \n",
    "\n",
    "    # Print the accuracy of the current model\n",
    "    print(accuracy_score(test_target, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6633 - loss: 11.6237\n",
      "Epoch 2/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5846 - loss: 10.6611 \n",
      "Epoch 3/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6138 - loss: 7.6850 \n",
      "Epoch 4/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5314 - loss: 5.0217  \n",
      "Epoch 5/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3748 - loss: 3.7097 \n",
      "Epoch 6/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3633 - loss: 1.9405\n",
      "Epoch 7/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4333 - loss: 0.9570\n",
      "Epoch 8/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6639 - loss: 0.6828\n",
      "Epoch 9/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6697 - loss: 0.6846 \n",
      "Epoch 10/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7073 - loss: 0.6131\n",
      "Epoch 11/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7045 - loss: 0.6047\n",
      "Epoch 12/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6909 - loss: 0.5901\n",
      "Epoch 13/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7230 - loss: 0.5629\n",
      "Epoch 14/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7344 - loss: 0.5505 \n",
      "Epoch 15/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7669 - loss: 0.5222\n",
      "Epoch 16/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7479 - loss: 0.5287\n",
      "Epoch 17/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7367 - loss: 0.5163 \n",
      "Epoch 18/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7431 - loss: 0.5139 \n",
      "Epoch 19/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7698 - loss: 0.4940 \n",
      "Epoch 20/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7759 - loss: 0.4846 \n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7712 - loss: 0.4508  \n",
      "Accuracy: 0.80\n",
      "Epoch 1/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6720 - loss: 1.3223\n",
      "Epoch 2/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6694 - loss: 0.9535\n",
      "Epoch 3/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6633 - loss: 0.7226\n",
      "Epoch 4/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6764 - loss: 0.6551 \n",
      "Epoch 5/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7312 - loss: 0.5588 \n",
      "Epoch 6/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7061 - loss: 0.5781 \n",
      "Epoch 7/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7544 - loss: 0.5530 \n",
      "Epoch 8/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7374 - loss: 0.5385 \n",
      "Epoch 9/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7948 - loss: 0.5106 \n",
      "Epoch 10/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7655 - loss: 0.5037 \n",
      "Epoch 11/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8123 - loss: 0.4832 \n",
      "Epoch 12/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8260 - loss: 0.4576 \n",
      "Epoch 13/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8143 - loss: 0.4626 \n",
      "Epoch 14/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8241 - loss: 0.4683 \n",
      "Epoch 15/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7932 - loss: 0.4747 \n",
      "Epoch 16/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8463 - loss: 0.4511\n",
      "Epoch 17/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8407 - loss: 0.4165\n",
      "Epoch 18/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8744 - loss: 0.3857\n",
      "Epoch 19/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8409 - loss: 0.3935\n",
      "Epoch 20/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8956 - loss: 0.3576 \n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9101 - loss: 0.3155  \n",
      "Accuracy: 0.91\n",
      "Epoch 1/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6119 - loss: 2.6383\n",
      "Epoch 2/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5122 - loss: 0.7660 \n",
      "Epoch 3/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6508 - loss: 0.6626 \n",
      "Epoch 4/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7042 - loss: 0.6123 \n",
      "Epoch 5/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6684 - loss: 0.6205 \n",
      "Epoch 6/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6897 - loss: 0.6237 \n",
      "Epoch 7/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6763 - loss: 0.6077 \n",
      "Epoch 8/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6953 - loss: 0.5851 \n",
      "Epoch 9/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6997 - loss: 0.5964 \n",
      "Epoch 10/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7033 - loss: 0.6023 \n",
      "Epoch 11/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6924 - loss: 0.5910 \n",
      "Epoch 12/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6694 - loss: 0.6067 \n",
      "Epoch 13/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6817 - loss: 0.5952 \n",
      "Epoch 14/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6734 - loss: 0.6136 \n",
      "Epoch 15/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6745 - loss: 0.5834 \n",
      "Epoch 16/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6913 - loss: 0.5990 \n",
      "Epoch 17/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6871 - loss: 0.6041 \n",
      "Epoch 18/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6970 - loss: 0.5889 \n",
      "Epoch 19/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6920 - loss: 0.5683 \n",
      "Epoch 20/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6939 - loss: 0.5812 \n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7135 - loss: 0.5709  \n",
      "Accuracy: 0.73\n",
      "Epoch 1/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.5656 - loss: 0.7269\n",
      "Epoch 2/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6860 - loss: 0.6113\n",
      "Epoch 3/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7001 - loss: 0.6055\n",
      "Epoch 4/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7248 - loss: 0.5756 \n",
      "Epoch 5/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7362 - loss: 0.5439 \n",
      "Epoch 6/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7822 - loss: 0.4639\n",
      "Epoch 7/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8074 - loss: 0.4340 \n",
      "Epoch 8/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8879 - loss: 0.3888\n",
      "Epoch 9/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9032 - loss: 0.2597\n",
      "Epoch 10/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9234 - loss: 0.2752\n",
      "Epoch 11/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9406 - loss: 0.1973 \n",
      "Epoch 12/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9568 - loss: 0.1804 \n",
      "Epoch 13/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9721 - loss: 0.1267 \n",
      "Epoch 14/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9724 - loss: 0.1163\n",
      "Epoch 15/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9757 - loss: 0.1140\n",
      "Epoch 16/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9775 - loss: 0.0785 \n",
      "Epoch 17/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9760 - loss: 0.0764\n",
      "Epoch 18/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9728 - loss: 0.0992 \n",
      "Epoch 19/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9822 - loss: 0.0529 \n",
      "Epoch 20/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9752 - loss: 0.0652 \n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9877 - loss: 0.0432  \n",
      "Accuracy: 0.98\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize an empty list to store the accuracy of each model\n",
    "accuracy_keras = []\n",
    "\n",
    "# Loop over each model in the list\n",
    "for model in Models_Keras:\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    model.fit(train_data, train_target, epochs=20)\n",
    "    \n",
    "    accuracy = model.evaluate(test_data, test_target)\n",
    "    \n",
    "    accuracy_keras.append(accuracy[1])\n",
    "    \n",
    "    print('Accuracy: %.2f' % accuracy[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the accuracy of MLP and Keras classifiers with varying hidden layers using bar charts\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.bar(range(4), accuracy_mlp, color=['purple', 'yellow', 'gray', 'orange'], alpha=0.7, edgecolor='black', linewidth=2)\n",
    "plt.xticks(range(4), ['(10,)', '(10, 20)', '(10, 20, 50)', '(10, 20, 50, 100)'])\n",
    "plt.title('MLP Classifier')\n",
    "plt.xlabel('Hidden Layers')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0, 1])\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.bar(range(4), accuracy_keras, color=['purple', 'yellow', 'gray', 'orange'], alpha=0.7, edgecolor='black', linewidth=2)\n",
    "plt.xticks(range(4), ['(10,)', '(10, 20)', '(10, 20, 50)', '(10, 20, 50, 100)'])\n",
    "plt.title('Keras Classifier')\n",
    "plt.xlabel('Hidden Layers')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0, 1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
